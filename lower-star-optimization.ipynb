{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c02e81",
   "metadata": {},
   "source": [
    "# Lower star filtration optimization\n",
    "\n",
    "**Goal:** \"degrade\" the persistence of an $H_0$ feature by changing pixel values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import H1_optimizer\n",
    "from numpy.linalg import lstsq\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "importlib.reload(H1_optimizer)\n",
    "import gudhi as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_graph(width, height, queen=True):\n",
    "    '''\n",
    "    Turn image into grid graph\n",
    "    '''\n",
    "    G = nx.grid_2d_graph(width, height)\n",
    "    if queen:\n",
    "        #add diagonal edges\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                if i < width - 1 and j < height - 1:\n",
    "                    G.add_edge((i, j), (i + 1, j + 1))\n",
    "                if i > 0 and j < height - 1:\n",
    "                    G.add_edge((i, j), (i - 1, j + 1))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec518a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_generators(image, PD, idx=None, image_graph=None, queen=True):\n",
    "    '''\n",
    "    Find the generators for a given persistence point\n",
    "    '''\n",
    "    if image_graph is None:\n",
    "        image_graph = get_image_graph(*image.shape, queen=queen)\n",
    "    birth_pixels = []\n",
    "    death_pixels = [None]\n",
    "    merge_pixels = []\n",
    "    for (b,d) in PD:\n",
    "        birth_pixel = np.unravel_index(np.argmin(np.abs(image - b)), image.shape)\n",
    "        birth_pixels.append(birth_pixel)\n",
    "        if d != float('inf'):\n",
    "            death_pixel = np.unravel_index(np.argmin(np.abs(image - d)), image.shape)\n",
    "            death_pixels.append(death_pixel)\n",
    "\n",
    "    if idx is None:\n",
    "        idxs = list(range(len(PD)))\n",
    "    else:\n",
    "        idxs = [idx]\n",
    "    for i in idxs:\n",
    "        b1, d1 = PD[i]\n",
    "        thresholded_graph = nx.subgraph(image_graph, [n for n in image_graph.nodes if image[n] <= d1+1e-5])\n",
    "        mergeable_pixels = [n for n in birth_pixels if image[n] <= b1 and nx.has_path(thresholded_graph, birth_pixels[i], n)]\n",
    "        if mergeable_pixels:\n",
    "            merge_pixel = min(mergeable_pixels, key = lambda i: image[i])\n",
    "            merge_pixels.append(merge_pixel)\n",
    "        else:\n",
    "            merge_pixels.append(None)\n",
    "\n",
    "    return [birth_pixels[i] for i in idxs], merge_pixels, [death_pixels[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb806432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_persistence(image, dim=0, queen=True):\n",
    "    '''\n",
    "    Find the persistence intervals for an image\n",
    "    '''\n",
    "    if queen:\n",
    "        scx = gd.CubicalComplex(top_dimensional_cells=image)\n",
    "    else:\n",
    "        graph = nx.grid_graph(image.shape)\n",
    "        grid_to_idx = {n: i for i, n in enumerate(graph.nodes)}\n",
    "        idx_to_grid = {i: n for i, n in enumerate(graph.nodes)}\n",
    "        graph = nx.relabel_nodes(graph, grid_to_idx)\n",
    "        scx = gd.SimplexTree()\n",
    "        for n in graph.nodes:\n",
    "            scx.insert([n])\n",
    "        for (i, j) in graph.edges:\n",
    "            scx.insert([i, j])\n",
    "        zero_skeleton = scx.get_skeleton(0)\n",
    "        for j in zero_skeleton:\n",
    "            scx.assign_filtration(\n",
    "                j[0], filtration=image[idx_to_grid[j[0][0]][0], idx_to_grid[j[0][0]][1]]\n",
    "            )\n",
    "        scx.make_filtration_non_decreasing()\n",
    "    \n",
    "    scx.persistence()\n",
    "    intervals = scx.persistence_intervals_in_dimension(dim)\n",
    "    return sorted(intervals, key=lambda x: -x[1] + x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25184b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_birth_cochain(b, d, birth_pixel, image, epsilon=0.1, boundary=None, image_graph=None, queen=True):\n",
    "    '''\n",
    "    Find the birth cochain for a given persistence point\n",
    "    '''\n",
    "    if image_graph is None:\n",
    "        image_graph = get_image_graph(*image.shape, queen=queen)                    \n",
    "    bplus = b + epsilon\n",
    "    subgraph_at_bplus = nx.subgraph(image_graph, [n for n in image_graph.nodes if image[n] <= bplus])\n",
    "    cc_of_birth_pixel_at_bplus = nx.node_connected_component(subgraph_at_bplus, birth_pixel)\n",
    "    cochain = np.zeros(image.shape)\n",
    "    for (i, j) in cc_of_birth_pixel_at_bplus:\n",
    "        cochain[i, j] = 1\n",
    "    return cochain/np.sum(cochain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39637b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_death_cochain(b, d, birth_pixel, image, epsilon=0.1, boundary=None, image_graph=None, queen=True):\n",
    "    '''\n",
    "    Find the death cochain for a given persistence point\n",
    "    '''\n",
    "    pixels = [(i,j) for i in range(image.shape[0]) for j in range(image.shape[1])]\n",
    "    binarized_image = np.array(image  < d, dtype=np.uint8)\n",
    "    before_death_nodes = [n for n in pixels if image[n] < d-epsilon]\n",
    "    after_death_nodes = [n for n in pixels if image[n] <= d + epsilon]\n",
    "    _, labels = cv2.connectedComponents(binarized_image, connectivity=8)   \n",
    "    pixel_label = labels[birth_pixel]\n",
    "    cc1 = [n for n in after_death_nodes if labels[n] == pixel_label]\n",
    "\n",
    "    if image_graph is None:\n",
    "        image_graph = get_image_graph(*image.shape, queen=queen)\n",
    "    if boundary is None:\n",
    "        boundary = np.array(nx.incidence_matrix(image_graph, oriented=True).todense())\n",
    "        boundary = boundary.T\n",
    "\n",
    "    boundary_operator = boundary.copy()\n",
    "    after_death_edges_idx_complement = [i for i, (u, v) in enumerate(image_graph.edges) if u not in after_death_nodes or v not in after_death_nodes]\n",
    "    after_death_nodes_idx_complement = [i for i, n in enumerate(image_graph.nodes) if n not in after_death_nodes]\n",
    "    boundary_operator = np.delete(boundary_operator, after_death_edges_idx_complement, axis=0)\n",
    "    boundary_operator = np.delete(boundary_operator, after_death_nodes_idx_complement, axis=1)\n",
    "\n",
    "    inactive_cols = [i for i, n in enumerate(after_death_nodes) if n in list(before_death_nodes)]\n",
    "    active_cols = [i for i, n in enumerate(after_death_nodes) if n not in list(before_death_nodes)]\n",
    "    restricted_boundary_operator = np.delete(boundary_operator, inactive_cols, axis=1)\n",
    "    f = np.array([int(n in cc1) for n in after_death_nodes])\n",
    "\n",
    "    x = lstsq(restricted_boundary_operator, -boundary_operator@f)[0]\n",
    "    extended_x = np.zeros(boundary_operator.shape[1])\n",
    "    extended_x[active_cols] = x\n",
    "    y = boundary_operator@(extended_x+f)\n",
    "    y = np.abs(y)/np.linalg.norm(y, ord=1)\n",
    "\n",
    "    abs_incidence = np.abs(boundary_operator).T\n",
    "    unrolled_partial_image = np.array([image[n] for n in after_death_nodes])\n",
    "    abs_incidence_with_values = unrolled_partial_image[:, None] * abs_incidence\n",
    "    abs_incidence_with_values[np.where(abs_incidence == 0)] = -np.inf\n",
    "\n",
    "    \n",
    "    only_maxes = np.zeros_like(abs_incidence_with_values)\n",
    "    min_indices = np.argmax(abs_incidence_with_values, axis=0)\n",
    "    rows = min_indices\n",
    "    cols = np.arange(abs_incidence_with_values.shape[1])\n",
    "    only_maxes[rows, cols] = 1\n",
    "    A = only_maxes @ y\n",
    "    gradient_image = np.zeros_like(image)\n",
    "    after_death_nodes = np.array(after_death_nodes)\n",
    "    gradient_image[after_death_nodes[:,0], after_death_nodes[:,1]] = A\n",
    "\n",
    "    return y, gradient_image, boundary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f620c",
   "metadata": {},
   "source": [
    "## Experiment with corrupted MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_fuse(image, name, method='cochains', seed=2025):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X = 1-image.copy()\n",
    "    plt.imshow(1-X, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'figs/MNIST_{name}_raw.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    queen = True\n",
    "    X[12,:] = 0.8\n",
    "    X[14,:] = 0.8\n",
    "    X[13,:] = 0.8\n",
    "    X += np.random.random(X.shape)*0.01\n",
    "    X = np.clip(X, 0, None)\n",
    "    X_old = X.copy()\n",
    "    plt.imshow(1-X_old, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'figs/MNIST_{name}_initial.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    image_graph = get_image_graph(*image.shape, queen=queen)\n",
    "    persistences = []\n",
    "\n",
    "    boundary = None\n",
    "    epsilons = [0.1]\n",
    "    gamma = 1e-1\n",
    "\n",
    "    if method == 'simplices':\n",
    "        for step in tqdm(range(1000)):\n",
    "            Xnew = X.copy()\n",
    "\n",
    "            PD = get_image_persistence(X, dim=0, queen=queen)\n",
    "            PD = sorted(PD, key=lambda i: -i[1] + i[0])\n",
    "            if len(PD) > 1:\n",
    "                if PD[1][1] - PD[1][0] > 0.01:\n",
    "                    second_idx = sorted(range(len(PD)), key=lambda i: -PD[i][1] + PD[i][0])[1]\n",
    "                    birth_pixels, merge_pixels, death_pixels = find_generators(X, PD, second_idx, image_graph=image_graph, queen=queen)\n",
    "                    Xnew[death_pixels[0]] -= gamma\n",
    "                    X = np.clip(Xnew, 0, None)\n",
    "                    persistences.append(PD[second_idx][1] - PD[second_idx][0])\n",
    "\n",
    "\n",
    "    if method == 'cochains':\n",
    "        for step in tqdm(range(1000)):\n",
    "            Xnew = X.copy()\n",
    "\n",
    "            PD = get_image_persistence(X, dim=0, queen=queen)\n",
    "            PD = sorted(PD, key=lambda i: -i[1] + i[0])\n",
    "            if len(PD) > 1:\n",
    "                if PD[1][1] - PD[1][0] > 0.01:\n",
    "                    second_idx = sorted(range(len(PD)), key=lambda i: -PD[i][1] + PD[i][0])[1]\n",
    "                    for epsilon in epsilons:\n",
    "                        birth_pixels, merge_pixels, death_pixels = find_generators(X, PD, second_idx, image_graph=image_graph, queen=queen)\n",
    "                        thisepsilon = epsilon\n",
    "                        y, A, boundary = find_death_cochain(\n",
    "                            PD[second_idx][0], PD[second_idx][1], birth_pixels[0], X,\n",
    "                            epsilon=thisepsilon, boundary=boundary, image_graph=image_graph, queen=queen\n",
    "                        )\n",
    "\n",
    "                        Xnew -= gamma*A/len(epsilons)\n",
    "\n",
    "\n",
    "                    X = np.clip(Xnew, 0, None)\n",
    "                    persistences.append(PD[second_idx][1] - PD[second_idx][0])\n",
    "\n",
    "    plt.imshow(1-X, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'figs/MNIST_{method}_{name}_final.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ef586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_loader import load_data\n",
    "train, validation, test = load_data()\n",
    "L = [0, 1, 2, 3, 4, 5, 7, 13, 15, 17]\n",
    "L = sorted(L, key = lambda x: train[1][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a942d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(train[0][L]):\n",
    "    np.random.seed(2025)\n",
    "    for trial in range(5):\n",
    "        split_and_fuse(sample.reshape(28,28), f'sample{i+1}_trial{trial+1}', method='simplices', seed=None)\n",
    "    for trial in range(5):\n",
    "        split_and_fuse(sample.reshape(28,28), f'sample{i+1}_trial{trial+1}', method='cochains', seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(train[0][L]):\n",
    "    split_and_fuse(sample.reshape(28,28), f'sample{i+1}', method='simplices', seed=2025)\n",
    "for i, sample in enumerate(train[0][L]):\n",
    "    split_and_fuse(sample.reshape(28,28), f'sample{i+1}', method='cochains', seed=2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965329c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
